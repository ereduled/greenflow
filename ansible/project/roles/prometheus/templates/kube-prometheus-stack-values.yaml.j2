---
# vim: set ft=yaml:
prometheus:
  prometheusSpec:
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    externalLabels:
      deployment_started_ts: "{{ deployment_started_ts }}"
    nodeSelector:
      node-role.kubernetes.io/control-plane: "true"
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
  additionalServiceMonitors:
    - name: scaphandre
      namespaceSelector:
        matchNames:
          - default
      selector:
        matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
              - scaphandre
      endpoints:
        - port: metrics
          interval: 5s
          relabelings:
            - action: replace
              sourceLabels:
                - __meta_kubernetes_pod_name
              targetLabel: pod
            - action: replace
              sourceLabels:
                - __meta_kubernetes_namespace
              targetLabel: namespace
prometheusOperator:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
  nodeSelector:
    node-role.kubernetes.io/control-plane: "true"
kubeApiServer:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubelet:
  serviceMonitor:
    relabelings:
      - sourceLabels: [__metrics_path__]
        targetLabel: metrics_path
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubeControllerManager:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
coreDns:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubeDns:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubeEtcd:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubeScheduler:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubeProxy:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kube-state-metrics:
  nodeSelector:
    node-role.kubernetes.io/control-plane: "true"
  prometheus:
    monitor:
      relabelings:
        - action: replace
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: instance
prometheus-node-exporter:
  prometheus:
    monitor:
      relabelings:
        - action: replace
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: instance
alertmanager:
  alertmanagerSpec:
    nodeSelector:
      node-role.kubernetes.io/control-plane: "true"
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
grafana:
  nodeSelector:
    node-role.kubernetes.io/control-plane: "true"
  # Grafana is Disabled now as metrics are stored on another analysis server
  enabled: false
  grafana.ini:
    auth.anonymous:
      enabled: true
      org_role: Admin
  sidecar:
    datasources:
      enabled: false
      defaultDatasourceEnabled: false
      # uid: prometheus
      # url: http://victoria-metrics-single-server.monitoring.svc.cluster.local:8428/
  datasources:
    datsources.yaml:
      apiVersion: 1
      datasources:
        - name: VictoriaMetrics
          type: prometheus
          url: http://victoria-metrics-single-server.default.svc.cluster.local:8428/
          access: proxy
          isDefault: true
  persistence:
    type: pvc
    enabled: true
    existingClaim: grafana-pvc
  initChownData:
    ## If false, data ownership will not be reset at startup
    ## This allows the prometheus-server to be run with an arbitrary user
    ##
    enabled: false
