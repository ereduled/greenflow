---
# vim: set ft=yaml:
prometheus:
  prometheusSpec:
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    externalLabels:
      deployment_start_ts: "{{ deployment_start_ts }}"
    remoteWrite:
      - url: http://victoria-metrics-single-server.monitoring.svc.cluster.local:8428/api/v1/write
    additionalServiceMonitors:
      - name: Scaphandre
        jobLabel: scaphandre
        selector:
          matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
                - scaphandre
          endpoints:
            - port: metrics
              interval: 5s
    nodeSelector:
      node-role.kubernetes.io/control-plane: "true"
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
prometheusOperator:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
  nodeSelector:
    node-role.kubernetes.io/control-plane: "true"
kubeApiServer:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubelet:
  serviceMonitor:
    relabelings:
      - sourceLabels: [__metrics_path__]
        targetLabel: metrics_path
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubeControllerManager:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
coreDns:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubeDns:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubeEtcd:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubeScheduler:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kubeProxy:
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
kube-state-metrics:
  nodeSelector:
    node-role.kubernetes.io/control-plane: "true"
  prometheus:
    monitor:
      relabelings:
        - action: replace
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: instance
prometheus-node-exporter:
  prometheus:
    monitor:
      relabelings:
        - action: replace
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: instance
alertmanager:
  alertmanagerSpec:
    nodeSelector:
      node-role.kubernetes.io/control-plane: "true"
  serviceMonitor:
    relabelings:
      - action: replace
        sourceLabels:
          - __meta_kubernetes_pod_node_name
        targetLabel: instance
grafana:
  nodeSelector:
    node-role.kubernetes.io/control-plane: "true"
  # Grafana is Disabled now as metrics are stored on another analysis server
  enabled: false
  grafana.ini:
    auth.anonymous:
      enabled: true
      org_role: Admin
  sidecar:
    datasources:
      enabled: false
      defaultDatasourceEnabled: false
      # uid: prometheus
      # url: http://victoria-metrics-single-server.monitoring.svc.cluster.local:8428/
  datasources:
    datsources.yaml:
      apiVersion: 1
      datasources:
        - name: VictoriaMetrics
          type: prometheus
          url: http://victoria-metrics-single-server.monitoring.svc.cluster.local:8428/
          access: proxy
          isDefault: true
  persistence:
    type: pvc
    enabled: true
    existingClaim: grafana-pvc
  initChownData:
    ## If false, data ownership will not be reset at startup
    ## This allows the prometheus-server to be run with an arbitrary user
    ##
    enabled: false
